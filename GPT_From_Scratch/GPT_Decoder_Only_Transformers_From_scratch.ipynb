{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zphGWV3CjrWp",
    "outputId": "9b8a875d-8cdd-4e2c-c8eb-cc2fde148e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input.txt', <http.client.HTTPMessage at 0x72639d0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "file_path = \"input.txt\"\n",
    "\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mGUgNzFujxVY"
   },
   "outputs": [],
   "source": [
    "with open('input.txt','r', encoding='utf-8') as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z-xpZERrj7Hp"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {char:idx for idx, char in enumerate(chars)}\n",
    "itos = {idx:char for idx, char in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda s: [itos[i] for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "neTv0kTykkHQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "data = torch.tensor(encode(text), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5Rlo-phPE6Jk"
   },
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab8gYzho1c3u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xp5J-6JptgbE"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class AutoRegressiveDataset(Dataset):\n",
    "  def __init__(self,data, block_size):\n",
    "    self.data = data\n",
    "    self.block_size = block_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)-self.block_size\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    X= self.data[idx:idx+self.block_size]\n",
    "    y= self.data[idx+1:idx+self.block_size+1]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eixq2vNNExFU"
   },
   "outputs": [],
   "source": [
    "dataset = AutoRegressiveDataset(data,BLOCK_SIZE)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xdu8I_l1W2Pf"
   },
   "outputs": [],
   "source": [
    "class MaskedMultiHeadAttention(nn.Module):\n",
    "  def __init__(self, emd_dim, heads=4, dropout = 0.2):\n",
    "    super(MaskedMultiHeadAttention, self).__init__()\n",
    "    assert emd_dim % heads == 0\n",
    "    self.heads = heads\n",
    "    self.head_dim = emd_dim//heads\n",
    "    self.scale = self.head_dim ** -0.5\n",
    "    self.multiHead = nn.Linear(emd_dim, emd_dim*3)\n",
    "    self.output = nn.Linear(emd_dim,emd_dim)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    B, T, C = x.shape\n",
    "    qkv = self.multiHead(x)\n",
    "    q, k, v = torch.chunk(qkv,3,dim=-1)\n",
    "    q = q.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "    k = k.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "    v = v.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "    attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "    tril = torch.tril(torch.ones(T,T))\n",
    "    attn_scores = attn_scores.masked_fill(tril==0, float('-inf'))\n",
    "    attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "    attn_probs_drop = self.dropout(attn_probs)\n",
    "    attn_output = torch.matmul(attn_probs_drop,v)\n",
    "    fn_attn_output = attn_output.permute(0, 2, 1, 3).reshape(B, T, C)\n",
    "    return self.output(fn_attn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VyzgbIaOvhSN"
   },
   "outputs": [],
   "source": [
    "class LayerNorm1D(nn.Module):\n",
    "  def __init__(self, dim, eps=1e-5):\n",
    "    super(LayerNorm1D, self).__init__()\n",
    "    self.gamma = nn.Parameter(torch.ones(dim))\n",
    "    self.beta = nn.Parameter(torch.zeros(dim))\n",
    "    self.eps = eps\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean = x.mean(-1,keepdim=True)\n",
    "    var = x.var(-1, unbiased=False, keepdim=True)\n",
    "    xhat = (x-mean)/torch.sqrt(var+self.eps)\n",
    "    return (self.gamma * xhat) +self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Dv0Si7jkxjQe"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.2):\n",
    "    super().__init__()\n",
    "    self.feed_forward_layer = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, output_dim),\n",
    "      nn.Dropout(dropout)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.feed_forward_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OIIEMSJ-zN9_"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self,embed_dim,heads=4):\n",
    "    super().__init__()\n",
    "    self.layer_norm1 = LayerNorm1D(embed_dim)\n",
    "    self.layer_norm2 = LayerNorm1D(embed_dim)\n",
    "    self.masked_multi_head_attn =  MaskedMultiHeadAttention(embed_dim, heads = 4)\n",
    "    self.feed_forward_layer = FeedForward(embed_dim, embed_dim*4, embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.masked_multi_head_attn(self.layer_norm1(x))\n",
    "    x = x + self.feed_forward_layer(self.layer_norm2(x))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FqJy6Ptr1tr0"
   },
   "outputs": [],
   "source": [
    "class AutoRegressiveModel(nn.Module):\n",
    "  def __init__(self, embed_dim, vocab_size, block_size = BLOCK_SIZE, heads=4, num_layers=4):\n",
    "    super().__init__()\n",
    "    self.block = nn.Sequential(*[Block(embed_dim,heads) for _ in range(num_layers)])\n",
    "    self.positional_embedding = nn.Embedding(block_size, embed_dim)\n",
    "    self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "    self.final_layer_norm = LayerNorm1D(embed_dim)\n",
    "    self.final_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "  def forward(self, x, targets = None):\n",
    "    _, T = x.shape\n",
    "    x_emb = self.embedding(x)\n",
    "    x_pos_emb = self.positional_embedding(torch.arange(T))\n",
    "    x = x_emb + x_pos_emb\n",
    "    block_output = self.block(x)\n",
    "    x_out = self.final_layer_norm(block_output)\n",
    "    return self.final_layer(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ux7BYbUSJO7p"
   },
   "outputs": [],
   "source": [
    "model = AutoRegressiveModel(embed_dim=128, vocab_size=vocab_size, block_size= BLOCK_SIZE, heads = 4)\n",
    "if os.path.exists(\"decoder_transformers_autoregressive_model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"decoder_transformers_autoregressive_model.pth\")) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2wtmRlIKKqoD"
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module, optimizer: torch.optim, criterion: nn.Module, dataloader: DataLoader, epochs: int):\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for X,y in dataloader:\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(X)\n",
    "      B, T, _ = outputs.shape\n",
    "      loss = criterion(outputs.reshape(B*T,-1),y.reshape(B*T))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      epoch_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YqqgcifRQbDj"
   },
   "outputs": [],
   "source": [
    "def val(model: nn.Module,dataloader: DataLoader):\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for X,y in dataloader:\n",
    "      outputs = model(X)\n",
    "      B, T, _ = outputs.shape\n",
    "      loss = criterion(outputs.reshape(B*T,-1),y.reshape(B*T))\n",
    "      val_loss += loss.item()\n",
    "    print(f\"Loss: {val_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cYOOEFBn0oGr"
   },
   "outputs": [],
   "source": [
    "def generate(model: nn.Module, start_seq: str =\"The\", epochs = 100):\n",
    "  current = start_seq\n",
    "  content = [c for c in start_seq]\n",
    "  for _ in range(epochs):\n",
    "    value = torch.tensor(encode(current[-BLOCK_SIZE:])).unsqueeze(0)\n",
    "    outputs = model(value).squeeze(0)\n",
    "    probs = torch.softmax(outputs[-1], dim=-1)\n",
    "    indices = torch.multinomial(probs,1).tolist()\n",
    "    output = decode(indices)\n",
    "    content.append(output[0])\n",
    "    current = current + output[0]\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v79becUvMXXE",
    "outputId": "8cc075be-5a8c-44f1-d2ab-900eec08c89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Loss: 1.8673\n",
      "Epoch: 2/10, Loss: 1.7148\n",
      "Epoch: 3/10, Loss: 1.6812\n",
      "Epoch: 4/10, Loss: 1.6630\n",
      "Epoch: 5/10, Loss: 1.6500\n",
      "Epoch: 6/10, Loss: 1.6407\n",
      "Epoch: 7/10, Loss: 1.6332\n",
      "Epoch: 8/10, Loss: 1.6272\n",
      "Epoch: 9/10, Loss: 1.6224\n",
      "Epoch: 10/10, Loss: 1.6177\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZDqFUIbDR33d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5803\n"
     ]
    }
   ],
   "source": [
    "val(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Qedoi5W5Sd0X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's none dangerous queen is royal footward's heaven, cousin must ready.\\nNothing do not a vessel you conlike away!\\n\\nKING RICHARD III:\\nI will not put off you would bear with a\\nmade seem, even consul,\\nAnd here's brother\\nMy father king his understands here in prince are not in you.\\n\\nSICINIUS:\\nO, here of your cold,\\nYou shall grace, good rather, sir? Your gracious our house.\\nForthwith my heaven, what are interfeit.\\nSee they last not hast servant, cravisitation?\\n\\nSecond Senator:\\nWhich or thought trust of mind all the dukedom that I had not that a cause.\\n\\nKING EDWARD IV:\\nHaste?\\n\\nANTIGONUS:\\nKatharing sturb of slow you liverce a sword yet she reled entreat fellow-bed\\nagainst him visit him not deposed for a custard thy rusted and spote this we.\\n\\nMENENIUS:\\nNo, much\\nIn any disgrim false is great names like that I stay not slander most cords.\\nBut let him;\\nSainty to deserve a word? When i' fail I\\nThat charge\\nTo hear it is my hell.\\n\\nPROSPERO:\\nBut request, thus with-kindred in the noble mendly day show not affection from my son of England, not\\nmade us used, his liet.\\n\\nCOMINIUS:\\nTell me, forgot,\\nThe sequenced luck and he be sit adost thou, and unchanged;\\nAnd some speak:\\nWhat, apothecame be true; stay woe thee thine merchful upon your under coming. Alady, what ballad it!\\n\\n\\nJULIET:\\nGood Catesby, never my brother day, Aumerle, what betime for, I will tell me and three to be:\\nGod not draw you hither did, ran you plake! Come, afill justly word stay: spote this grow; and thine is every on potion.\\n\\nSICINIUS:\\nI am prank catchly courage,\\nI'll give me; I even hath suit, take so\\nAgainst his like a murder made.\\n\\nstand, as you have he ha fretty me too to dost not sorrow in confined but that news?\\nLady, thus but base to the casant it you\\ncannot home, and effect come to choice again his right to fool one outided\\nThan I am tyrant brawledge and ope's a beauty disacontents?\\n\\nDUCHESS OF YORK:\\nAnd we preserve this eyest show they prove.\\n\\nKING EDWARD IV:\\nA misdain. Drows' ssorcn?\\nShall sweetness\\nFrom him that thou cares be drunken thy draw him what you shall let us good soul!\\nO' the 'will say you; or from my ducations come would thou shalt not go let not cracks\\nOf London, if you shall be;\\nIf not or a uslet sute,\\nMisplay who recking a directed and\\nAnd since,\\nThou talk up,\\nThat stand;\\nNow of Warwick; who hack to lie here,\\nBoth after name Padua; and no lies on my life, your queen,\\nWhose sorry him? ha!\\nbefore!\\nThis far else dyard;\\nIf thou wert thou haston too; calm the king to and seem'd?\\nTake her blood, and by in the trade,\\nThough says have a had make the trial to look, sir.\\n\\nBIANCA:\\nThese fortune.\\nWhat means,' quoth mine I ommon for safety keep-did do.' We and down poison and not resoul's mother? What, never to accessity to-day\\nTo stay.\\n\\nSecond Murderer:\\nWill thou dost thou liest.\\n\\nJULIET:\\nWhere is sen Montague.\\n\\nGRUMIO:\\nVouch, and Caius,\\nthreaten imprisonment to say 'tis a course.\\n\\nGRUMIO:\\nThink this! nurse; and all he comes, Friar\\nCan lewd how a godless. Well, he'll dispossible us,\\nShall I shall beseech you are strong stupes of Irance!\\nHis is true,\\nHold me late 'masters: where you find stop death. Come, I am 'twould scarce rescore. But I see so sure,\\nAnd see the clambs.\\n\\nCAMILLO:\\nSo paled of mad pomp, O long but shower friends, lovely eye.\\n\\nROMEO:\\nWhere is souls of quiet on:\\nHow stand;\\nBut good heart.\\n\\nFirst Gentleman is would prove the there and we came not eye lay away.\\n\\nHERMIONE:\\nTo hold and sound but a king.\\n\\nROMEO:\\nAnd with cheering Romeo lives help thee, by a city, I have depends\\nTo they would not voice, good, thy thrust peneral is a plant of this mindness.\\n\\nANGELO:\\nThe wisdom passess of cost not to the visite, it is, and meet,\\nAnd meeting age.\\n\\nANGELO:\\nThus a lies\\nThat school-face, and gods,\\nand make this rack'd\\nfrom the shepherd:\\nSir, with the hand.\\n\\nHENRY BOLINGBROKE:\\nHow no, for her cold cut alone. I pray they are old never too devour\\nThat sky, and whence added,\\nAnd lose thou, make it, make\\nI see that would a tender, where?\\nAnd yet so even your ear\\nMay shepherd:\\nMarry, hedded thee, Caius Marcius. Well, girl of ghostly.\\n\\nVOLUMNIA:\\nWhy, use--\\nNay, I shall the faults have looks?\\nI know both away.\\n\\nSICINIUS:\\nGo, fie, pray you,\\nYet to take my field father man for't. Come, Buckill'd look him mine of curder his like him my bed forced, I shall compass of his chour\\nMightop of thee.\\nWhat's facise, the sure in queen.\\n\\nSICINIUS:\\n\\nSecond Lord:\\nLook on ere but service from merchange\\nThe kites, here come an entertain'd\\nFour royalties and fetched worth kneel possible\\nTo talk of crown of Hortensio,\\nThat multtingman love gone to him that wringly shouldst thine.\\n\\nYORK:\\nThou art company:\\nMy name that my brother's Baptista, believe thee and will courtuney.\\nHa time and suborn the preceived you like so sleep for quickward's heartle that word say 'What, that she best him, with command, vesself. Plantagenet, humour,\\nAnd thou there.\\n\\nVINCENTIO:\\nHear his death, I am\\nTo my dear come; he discovery change four won,\\nOf the king to that I did goeman\\nIs virtuous,\\nWho assever seemed be death.\\n\\nEDWARD IV:\\nFor his bright-day; and the Duke of York; for you are city had quick and sighs.\\n\\nCLARENCE:\\nRomeo have every shepherd:\\nWhile formal return to long from succeds.\\n\\nKING RICHARD III:\\nDo not no\\nprovator!\\n\\nBRUTUS:\\nI am sup chy.\\n\\nGLOUCESTER:\\nWelcome, I had, superfection would prophet, I pray there;\\nPost:\\nHe are every spoke of a while I secret them to-for not could true! what my nimbly father, but think you think sight.\\n\\nKOTH:\\nThus I am, an all do sink, I have we see myself make it no clear and for not for could ever our spoken, name of death,\\nOnly sorrow\\nAt the church:\\nHe would be way. Come, come, are youth, go within these thee I remember me to him.\\n\\nBRUTUS:\\nYou think\\nWhich yet most amazed prove to the shook more.\\n\\nEDWARD:\\nI pray his doors he reasons,\\nWhich is your highness' treble welcome, but a muff'd him,\\nGod kept remember,\\nWhich, in command,\\nWho hath hem darest she though and proport; but he may from his fairly ducate.\\nFarewell:\\nThat she must them so I more a life with remember, and whence,\\nO more hold me by your woe on thy particul\\nFor Caesar me steed him of good order of my life.\\n\\nANTONIO:\\nHow now, God be: let my son.\\n\\nPOMPEY:\\nNay, Warwick, am I for before, as welk are turns up,\\nAnd if itself.' I have been and all hear forswear your comforts,\\nAffect and unthy of me: I say in name:\\nCominius sorrow: but lord Bohemia, and desty!\\n\\nCORIOLANUS:\\nHe'ld gates, as in an intends away down: your love!\\nWhy then, Ctise, I do, 'twas not have thou\\nshadest thou foul such by sue our speech!\\n\\nKING RICHARD II:\\nAnd is it is: cause no doubted friends are 'not to shall not your tongue heaven alive,\\nYet he sense; prosperity gled love; but account\\nMore no the\\nbeseech your woful patricion, when I know it you go'd with the sake:\\nFor like again.\\n\\nVINCENTIO:\\nWent eye?\\nSailors' bosoul!\\n\\nGLOUCESTER:\\nHeaden him see frank non that to her one Derby you here.\\nStay, let it is grave false rusing his dashop Lodowice, and beloved caitiff.\\n\\nShepherd:\\n'Tis not act must have you back.\\n\\nLORD FITZWATER:\\nTo my burning: can this mother! I have another; and that seem and there, but remember, what thereof dead; but ignorant true days! Romeo, Juliet;\\nAnd hunto him after?\\n\\nHENRY BOLINGBROKE:\\nIt is noler remia:\\none homical kissess.\\nSprise him how us fair coming for my grace would have been pray the power.\\nBut there, before an own under oath to my heart an impirage; and thou stook?\\n\\nGREMIO:\\nIn mean our fire must might you have, leisure to demand:\\nHastings to the city; so in the Lord of a mind'--daughters have ends\\nAnd make hold;\\nKind Richard, to-time; I must all that Kate.\\n\\nPETRUCHIO:\\nCatesby like dead, if I my sword of all, Sir Jerusal years. Pray  to a woman ere?\\n\\nSecond Bianca, do't.\\n\\nDUKE VINCENTIO:\\nAy, serve uncle confess'd by her\\nEre resolute?\\nSuprise of word,--as deaf wounds, and pother cousin of wisdom's sped above to the fury; now'st proves, and be broken his majesty.\\n\\nYORK:\\nCome one of to my coz it is too rasc; but I pervant:\\nNot in's young and that being for pity's rust and so satisfy it.\\nMy heart is he know to noble banished house not your lord--\\n\\nKING EDWARD IV:\\nHear my soults doth afquires for Sicilia; they say rise thy foe,\\nThat may hence, then\\nthey may king must be\\nthe hollow that we'll be plague I warrant,\\nOur oin--to persuade ere thy king of pretty name, their love\\nHere might,\\nAnd seeing\\nThan speak it;\\nThe valour.\\nBut of the first thou dissemble,\\nShepherd:\\nPerhaps moon stay self a to 't.\\n\\nSecond Lord of this stender than left; which we be a god it to heaving one and you not must\\nI had from most summer first thousand, present not about,\\nBrothers, but little Plantagenet:\\nHow he's safe, rather on, Elbow indeed,\\nAnd with other chop out loves in embassale; and you poor gracious wife: after my son and there love out,\\nWith battler,\\nAnd place,\\nBy death Warwick, and your conger prayers.\\n\\nTRANIO:\\nMeaning I said, for I were every Buckingham,\\nHave I do the day blest-leased out thy spair of the shadow'll that they thou do\\nlet him by Buckingham, it shall do\\ntribunes\\nfor live\\nWhich decreed again? it was?\\n\\nFirst Murderer:\\nThe one Polixenes\\nAs I between and she shall ruin of King of acquainted me and not do be afford! Yet may not our life was be antickly drink no believe none lady.\\n\\nPOLIXENES:\\nMy yielding brother.\\n\\nKATHARINA:\\nI played two meet you help together, thou in our body's young thee: if the bed;\\nFor thee joy;\\nThe gust it there, courage night, virtuous,\\nTen that the supret'sness and rather, pale\\nBut perform you here to your brother, that may cousin, on my master?\\n\\nCIRINA:\\nGo to her Juliet, you of swell reflect, when I, forbid! who's lovely leave own can yet refuse, a burn thee,\\nBut now gentleman we be pon him,\\nWe'll grow my wife.\\n\\nPOMPEY:\\nWas obvid\\nSome and ever\\nI hope.\\n\\nHORTENSIO:\\nO, care in passages with the most be onpense not you are read of thy bitiful father, I ccould be have for so father's degreet friends, and long for the woe! when only tongue,\\nThat I shall be such plucks thee forth; for I might him sup\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = generate(model, epochs = 10000)\n",
    "''.join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"decoder_transformers_autoregressive_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
