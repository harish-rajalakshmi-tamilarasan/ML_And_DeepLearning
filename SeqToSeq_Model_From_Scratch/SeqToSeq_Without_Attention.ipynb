{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f56267-e047-408b-b700-bfd5656dd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "path = r'C:\\\\Users\\\\harish-4072\\\\Downloads\\\\eng_french.csv'\n",
    "df = pd.read_csv(path, names=['English','French'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cf0886-675a-40c5-9619-a987c0a4c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  \n",
    "    tokens = text.split()  \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1667dd2-4968-4760-8d63-c92c560667b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = df['English'].dropna().apply(preprocess_text)\n",
    "english_vocab = Counter([token for sentence in english_sentences for token in sentence])\n",
    "\n",
    "french_sentences = df['French'].dropna().apply(preprocess_text)\n",
    "french_vocab = Counter([token for sentence in french_sentences for token in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc83af3-e8c3-4d21-bfa2-7fc287c5839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_token_to_id = {token: idx + 1 for idx, token in enumerate(english_vocab)}  # Start from 1 to reserve 0 for padding\n",
    "french_token_to_id = {token: idx + 3 for idx, token in enumerate(french_vocab)}\n",
    "\n",
    "english_token_to_id['<PAD>'] = 0\n",
    "\n",
    "french_token_to_id['<PAD>'] = 0\n",
    "french_token_to_id['<SOS>'] = 1\n",
    "french_token_to_id['<EOS>'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6039b86c-6d89-4c69-99da-5ed3a7b7fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_id_to_token= {value:key for key,value in french_token_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b24936-8c74-4a24-a580-1554e1417daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab_size = len(english_token_to_id)\n",
    "french_vocab_size = len(french_token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388e6b58-a436-4f5b-a1a6-bcd61c2a405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(tokens,token_to_id):\n",
    "    return [token_to_id.get(token,0) for token in tokens]\n",
    "\n",
    "english_sequences = english_sentences.apply(lambda x: tokenize_text(x, english_token_to_id))\n",
    "french_sequences = french_sentences.apply(lambda x: tokenize_text(x, french_token_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc48382b-5a52-4c91-9a7d-5132007a48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sos_eos(tokens):\n",
    "    return [1]+tokens+[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aba5ed7-bf55-48d5-a86b-e4cc33d353ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_sequences = french_sequences.apply(lambda x: add_sos_eos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817ec228-6b92-49e7-9d32-b3b44ab5aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesDataset(Dataset):\n",
    "    def __init__(self,english_sequences,french_sequences):\n",
    "        self.english_sequences = english_sequences\n",
    "        self.french_sequences = french_sequences\n",
    "        assert len(self.english_sequences) == len(self.french_sequences)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sequences)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        X= self.english_sequences[idx]\n",
    "        y= self.french_sequences[idx]\n",
    "        return torch.tensor(X,dtype=torch.long),torch.tensor(y,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "446f7892-79c8-44c8-8499-ca14d0ccfbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    X,y = zip(*batch)\n",
    "    X_lengths = [len(item) for item in X]\n",
    "    y_lengths = [len(item) for item in y]\n",
    "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "    y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "    return X_padded, y_padded, X_lengths, y_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aa88e90-72cd-4224-b414-7a9f43cb3b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_temp, french_temp = english_sequences[:1000].reset_index(drop=True), french_sequences[:1000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e400b7cc-0009-476c-8025-86442d5d5c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_temp),len(french_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413527a1-4b0f-47b8-a2f0-a50cfd5d4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentencesDataset(english_temp,french_temp)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True,collate_fn = collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False,collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f307a2b2-d3e4-464d-b975-f9b0282daa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 30\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "SRC_VOCAB_SIZE = english_vocab_size  \n",
    "PAD_IDX = 0 \n",
    "TRG_VOCAB_SIZE = french_vocab_size  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3dc8b5d-ed00-4473-a5dc-37a8fa12172a",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, dropout,padding_idx):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=padding_idx)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, lengths):\n",
    "        \"\"\"\n",
    "        :param src: Source sequence (batch_size, src_len)\n",
    "        :return: Encoder outputs and hidden states\n",
    "        \"\"\"\n",
    "        embedded = self.dropout(self.embedding(src)) \n",
    "        packed_input = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_input) \n",
    "        outputs, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        return outputs, hidden, cell\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8f7413-6c05-41f6-8296-263fda451954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True, bidirectional=False)\n",
    "        self.out = nn.Linear(hidden_dim,output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, target, hidden, cell):\n",
    "        embedded = self.dropout(self.embedding(target)) \n",
    "        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        outputs = self.out(outputs.squeeze(1))\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6df9aa5-5813-4091-93e7-07db1db4af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(SeqToSeq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, src_lengths, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        :param src: Source sequence (batch_size, src_len)\n",
    "        :param trg: Target sequence (batch_size, trg_len)\n",
    "        :param src_lengths: Lengths of the source sequences\n",
    "        :param trg_lengths: Lengths of the target sequences\n",
    "        :param teacher_forcing_ratio: Probability of using teacher forcing\n",
    "        :return: Decoder outputs (batch_size, trg_len, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        output_dim = self.decoder.out.out_features\n",
    "\n",
    "        # Tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim)\n",
    "\n",
    "        # Encode the source sequence\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_lengths)\n",
    "\n",
    "        # First input to the decoder is the <sos> token\n",
    "        input = trg[:, 0].unsqueeze(1)  # (batch_size, 1)\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden[-2:, :, :], cell[-2:, :, :])  # Decoder forward pass\n",
    "            outputs[:, t, :] = output  # Store the output\n",
    "\n",
    "            # Decide whether to use teacher forcing\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1).unsqueeze(1)  # Get the predicted next token\n",
    "\n",
    "            input = trg[:, t].unsqueeze(1) if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d221c5f3-a43a-4285-abf1-ceda45a2c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    input_dim=SRC_VOCAB_SIZE,\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    padding_idx = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ef671ff-19bc-44c6-8a2b-25b711d6f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14393, 28062)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE, TRG_VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d8f0581-49c5-45a0-b79e-1fdd67c40718",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(\n",
    "    output_dim=TRG_VOCAB_SIZE,\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3554f5e4-dc03-4274-9a33-c13777ab7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harish-4072\\AppData\\Local\\Temp\\ipykernel_23932\\2958523338.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"seq2seq_model_weights.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model = SeqToSeq(encoder, decoder)\n",
    "if os.path.exists(\"seq2seq_model_weights.pth\"):\n",
    "    model.load_state_dict(torch.load(\"seq2seq_model_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "701b9697-09e7-44a3-9f1e-f17796a5a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c61fb32d-1915-4b24-86c4-8c854ce1ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef6d37ac-79bb-4ca0-8f91-9d52cd9d4df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for src, trg, src_lengths,_ in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(src, trg, src_lengths)\n",
    "#         output = output[:, 1:].reshape(-1, output.shape[-1])  \n",
    "#         trg = trg[:, 1:].reshape(-1) \n",
    "#         loss = criterion(output, trg)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     # torch.save(model.state_dict(), \"seq2seq_model_weights.pth\")\n",
    "#     print(f\"Epoch: {epoch + 1}/{EPOCHS}, Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30a9078b-391f-4286-94b3-ffbd4608218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"seq2seq_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7afcf1c-b7e9-4890-9236-293220d66170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# epoch_loss = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for src, trg, src_lengths, _ in val_loader:\n",
    "            \n",
    "#         output = model(src, trg, src_lengths, teacher_forcing_ratio=0.0)\n",
    "#         output = output[:, 1:].reshape(-1, output.shape[-1])  # Ignore <sos> token\n",
    "#         trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "#         loss = criterion(output, trg)\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     print(epoch_loss / len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cca2ed4-e7ea-4f83-b883-7683db980901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, src, src_lengths, trg_vocab, max_len=50):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_lengths)\n",
    "        print(encoder_outputs.shape)\n",
    "        # Start with <sos> token\n",
    "        trg_vocab_size = model.decoder.out.out_features\n",
    "        input = torch.tensor([[1]])  # (1, 1)\n",
    "        predictions = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, cell = model.decoder(input, hidden, cell)\n",
    "            \n",
    "            top1 = output.argmax(1)  # Get the token with highest probability\n",
    "            predictions.append(top1.item())\n",
    "            if top1.item() == trg_vocab['<EOS>']:\n",
    "                break\n",
    "\n",
    "            input = top1.unsqueeze(1)  # Use the predicted token as input for the next step\n",
    "    return [french_id_to_token[idx] for idx in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d06ac63-1dfe-4b35-bfba-644770bb50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I like you\"\n",
    "sentence = preprocess_text(sentence)\n",
    "sentence = tokenize_text(sentence, english_token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53a387b8-d8ce-45f1-abb1-e1699e3aa746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 264, 92]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1031d4f-35f7-4493-aca0-cafe3164edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['je', 'taime', '<EOS>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(model, torch.tensor([sentence]),torch.tensor([len(sentence)]),french_token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c296d0f-fb15-4502-94c7-2bd1914644c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
